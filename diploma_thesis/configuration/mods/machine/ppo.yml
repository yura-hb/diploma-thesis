kind: 'rl'
parameters:
  model:
    kind: 'deep_multi_rule'
    parameters:
      __rules__: ''

      policy:
        kind: 'discrete_action'
        parameters:
          policy_method: 'independent'

          value_model:
            __model__: ''

          action_model:
            __model__: ''

          action_selector:
            kind: 'sample'
            parameters:
              is_distribution: False

  __encoder__: ''

  trainer:
    kind: 'ppo'
    parameters:
      policy_step_ratio: 0.2
      entropy_regularization: 0.01
      epochs: 4

      loss:
        kind: 'cross_entropy'
        parameters:
          reduction: 'none'

      value_loss:
        kind: 'mse'

      optimizer:
        model:
          kind: 'adam'
          parameters:
            lr: 0.001

      memory:
        kind: 'replay'
        parameters:
          size: 8192
          batch_size: 128
          prefetch: 8
#          sampler:
#            kind: 'slice'
#            parameters:
#              slice_len: 64
#              strict_length: False
#              traj_key: [ 'info', 'episode' ]
#              end_key: 'done'

      return:
        kind: 'gae'
        parameters:
          discount_factor: 0.4
          lambda: 0.95
